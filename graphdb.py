import json
import os
import numpy as np
from llm import llm
from collections import Counter
from sentence_transformers import SentenceTransformer

DATABASE = "neo4j"

embedding_model = SentenceTransformer("all-MiniLM-L6-v2")  # ë” ìž‘ì€ ëª¨ë¸ ì‚¬ìš©


def create_summary_context(trace_data):
    context_lines = []

    def get_tag_value(tags, key, default=None):
        for tag in tags:
            if tag.get("key") == key:
                return tag.get("value")
        return default

    sigma_alerts = Counter()
    process_flows = Counter()
    network_events = Counter()
    file_events = Counter()
    registry_events = Counter()

    for span in trace_data.get("spans", []):
        tags = span.get("tags", [])
        event_name = get_tag_value(tags, "EventName", "")
        process_image = get_tag_value(tags, "Image")
        process_name = os.path.basename(process_image or "N/A")

        # Sigma ë£° íƒì§€
        rule_title = get_tag_value(tags, "sigma.rule_title")
        if rule_title:
            sigma_alerts[f"ê·œì¹™: {rule_title}, í”„ë¡œì„¸ìŠ¤: {process_name}"] += 1

        # í”„ë¡œì„¸ìŠ¤ ìƒì„± íë¦„
        if "ProcessCreate" in event_name:
            parent_image = get_tag_value(tags, "ParentImage")
            if parent_image and process_image:
                process_flows[
                    f"'{os.path.basename(parent_image)}'ê°€ '{process_name}'ë¥¼ ì‹¤í–‰"
                ] += 1

        # ë„¤íŠ¸ì›Œí¬/íŒŒì¼/ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ë²¤íŠ¸
        if "NetworkConnect" in event_name:
            dest_ip = get_tag_value(tags, "DestinationIp")
            dest_port = get_tag_value(tags, "DestinationPort")
            if dest_ip and dest_port:
                network_events[
                    f"[ë„¤íŠ¸ì›Œí¬] '{process_name}'ê°€ '{dest_ip}:{dest_port}'ë¡œ ì—°ê²°"
                ] += 1
        elif "FileCreate" in event_name:
            target_file = get_tag_value(tags, "TargetFilename")
            if target_file:
                file_events[
                    f"[íŒŒì¼] '{process_name}'ê°€ '{target_file}' íŒŒì¼ì„ ìƒì„±"
                ] += 1
        elif "RegistryValueSet" in event_name:
            target_object = get_tag_value(tags, "TargetObject")
            if target_object:
                registry_events[
                    f"[ë ˆì§€ìŠ¤íŠ¸ë¦¬] '{process_name}'ê°€ '{target_object}' í‚¤ ê°’ì„ ìˆ˜ì •"
                ] += 1

    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    if sigma_alerts:
        context_lines.append("### Sigma Rule íƒì§€ ìš”ì•½:")
        for item, count in sigma_alerts.most_common():
            context_lines.append(f"- {item} ({count}íšŒ)")
    if process_flows:
        context_lines.append("\n### ì£¼ìš” í”„ë¡œì„¸ìŠ¤ ìƒì„± íë¦„:")
        for item, count in process_flows.most_common():
            context_lines.append(f"- {item} ({count}íšŒ)")
    if network_events or file_events or registry_events:
        context_lines.append("\n### ê¸°íƒ€ ì£¼ìš” ì´ë²¤íŠ¸:")
        for item, count in network_events.most_common(5):
            context_lines.append(f"- {item} ({count}íšŒ)")
        for item, count in file_events.most_common(5):
            context_lines.append(f"- {item} ({count}íšŒ)")
        for item, count in registry_events.most_common(5):
            context_lines.append(f"- {item} ({count}íšŒ)")

    return "\n".join(context_lines)


def summarize_trace_with_llm(trace_input, prompt_template):
    if isinstance(trace_input, str):
        with open(trace_input, "r", encoding="utf-8-sig") as f:
            trace_data = json.load(f)
    else:
        trace_data = trace_input

    summary_context = create_summary_context(trace_data)
    final_prompt = prompt_template.replace(
        "[ë¶„ì„í•  JSON ë°ì´í„°ê°€ ì—¬ê¸°ì— ì‚½ìž…ë©ë‹ˆë‹¤]", summary_context
    )

    try:
        response = llm.invoke(final_prompt)
        raw_content = response.content
        if not raw_content.strip():
            return {"error": "LLMìœ¼ë¡œë¶€í„° ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤."}

        cleaned_content = raw_content.strip()
        if cleaned_content.startswith("```json"):
            cleaned_content = cleaned_content.split("\n", 1)[1]
        if cleaned_content.endswith("```"):
            cleaned_content = cleaned_content.rsplit("\n", 1)[0]

        analysis_result = json.loads(cleaned_content.strip())
        return analysis_result
    except json.JSONDecodeError:
        return {
            "error": "LLMì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "raw_response": raw_content,
        }
    except Exception as e:
        return {"error": f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}


def long_summary(
    driver,
    summary_text,
    structural_similarity,
    indirect_connections,
    semantic_top_traces,
    top_k=3,
):
    """êµ¬ì¡°ì  ìœ ì‚¬ì„±, ê°„ì ‘ ì—°ê²°, ì˜ë¯¸ì  ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™œìš©í•œ ìƒì„¸ ìš”ì•½ ìƒì„±"""

    # ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤ IDë§Œ ì¶”ì¶œ (ìƒìœ„ 3ê°œ)
    similar_trace_ids = [t["trace_id"] for t in semantic_top_traces[:top_k]]

    # LLMì„ í™œìš©í•œ êµ¬ì¡°ì  ë¶„ì„ í”„ë¡¬í”„íŠ¸
    analysis_prompt = """
ë‹¤ìŒì€ ìƒˆë¡œìš´ ê³µê²© íŠ¸ë ˆì´ìŠ¤ì™€ ê¸°ì¡´ íŠ¸ë ˆì´ìŠ¤ë“¤ ê°„ì˜ êµ¬ì¡°ì  ìœ ì‚¬ì„± ë¶„ì„ ê²°ê³¼ìž…ë‹ˆë‹¤.

ìž…ë ¥ ë°ì´í„°ëŠ” ë‘ ê°€ì§€ìž…ë‹ˆë‹¤:
1. structural_similarity: ê° íŠ¸ë ˆì´ìŠ¤ë³„ë¡œ ê³µí†µëœ ì—”í‹°í‹°ì™€ ì¼ì¹˜ ê°œìˆ˜(entity_match_count)
2. indirect_connections: ì—”í‹°í‹° ê°„ì˜ ê°„ì ‘ ì—°ê²° ê´€ê³„(ìµœëŒ€ 2-hop ê²½ë¡œ)

ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ëž˜ ë‚´ìš©ì„ **ìžì—°ì–´ë¡œ ì¢…í•©ì ìœ¼ë¡œ ìš”ì•½**í•˜ì„¸ìš”.

ìš”ì•½ ì‹œ í¬í•¨í•  ë‚´ìš©:
- ì „ë°˜ì ì¸ êµ¬ì¡°ì  ìœ ì‚¬ì„± ê²½í–¥  
  (ê³µí†µ ì—”í‹°í‹°ê°€ ë§Žì€ íŠ¸ë ˆì´ìŠ¤ë“¤ì˜ íŠ¹ì§•, ì£¼ìš” ìœ ì‚¬ êµ¬ì¡°ë‚˜ ê³µê²© íŒ¨í„´)
- ë°˜ë³µì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” í•µì‹¬ ì—”í‹°í‹°(Process, File, IP, Registry ë“±)
- ê°„ì ‘ ì—°ê²°ì—ì„œ ì˜ë¯¸ ìžˆëŠ” ê´€ê³„  
  (ì˜ˆ: ë™ì¼ íŒŒì¼ì„ ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ ì ‘ê·¼, íŠ¹ì • IPë¡œì˜ ê³µí†µ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë“±)
- ì „ì²´ì ìœ¼ë¡œ ì–´ë–¤ ê³µê²© íë¦„ ë˜ëŠ” ì „ìˆ ê³¼ ìœ ì‚¬í•œì§€  
- ë¶„ì„ ê²°ê³¼ì—ì„œ ë„ì¶œë˜ëŠ” êµ¬ì¡°ì  ì¸ì‚¬ì´íŠ¸ë‚˜ ì‹œì‚¬ì   

ì¶œë ¥ì€ ìžì—°ìŠ¤ëŸ¬ìš´ ë¶„ì„ ë³´ê³ ì„œì²˜ëŸ¼ ìž‘ì„±í•˜ì„¸ìš”.  
ë¶ˆí•„ìš”í•œ í˜•ì‹ ì—†ì´ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì •ë¦¬í•˜ê³ ,  
í•„ìš”í•˜ë©´ bullet pointë¥¼ ì‚¬ìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.

ë°ì´í„°:
{
  "structural_similarity": {{ structural_similarity }},
  "indirect_connections": {{ indirect_connections }}
}
"""

    try:
        # ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = analysis_prompt.replace(
            "{{ structural_similarity }}",
            json.dumps(structural_similarity, ensure_ascii=False),
        )
        prompt = prompt.replace(
            "{{ indirect_connections }}",
            json.dumps(indirect_connections, ensure_ascii=False),
        )

        # LLMìœ¼ë¡œ êµ¬ì¡°ì  ë¶„ì„ ìˆ˜í–‰
        response = llm.invoke(prompt)
        structural_analysis = response.content.strip()

        print("ðŸ”Ž êµ¬ì¡°ì  ìœ ì‚¬ì„± ë¶„ì„ ìš”ì•½ ê²°ê³¼:")
        print(response.content)

        # ì „ì²´ ìƒì„¸ ìš”ì•½ ìƒì„±
        long_summary_text = f"""## ìƒì„¸ ë¶„ì„ ìš”ì•½

### ì›ë³¸ íŠ¸ë ˆì´ìŠ¤ ìš”ì•½
{summary_text}

### ìœ ì‚¬í•œ íŠ¸ë ˆì´ìŠ¤ ë¶„ì„
- ìƒìœ„ {len(similar_trace_ids)}ê°œ ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤: {', '.join([tid[:8] + '...' for tid in similar_trace_ids])}

### êµ¬ì¡°ì  ìœ ì‚¬ì„± ë° ì—°ê²° ë¶„ì„
{structural_analysis}
"""

    except Exception as e:
        # LLM ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ìš”ì•½ ë°˜í™˜
        long_summary_text = f"""
## ìƒì„¸ ë¶„ì„ ìš”ì•½

### ì›ë³¸ íŠ¸ë ˆì´ìŠ¤ ìš”ì•½
{summary_text}

### ìœ ì‚¬í•œ íŠ¸ë ˆì´ìŠ¤ ë¶„ì„
- ìƒìœ„ {len(similar_trace_ids)}ê°œ ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤: {', '.join([tid[:8] + '...' for tid in similar_trace_ids])}

### êµ¬ì¡°ì  ìœ ì‚¬ì„±
{len([s for s in structural_similarity if s['entity_match_count'] > 0])}ê°œì˜ íŠ¸ë ˆì´ìŠ¤ì—ì„œ êµ¬ì¡°ì  ìœ ì‚¬ì„± ë°œê²¬

### ê°„ì ‘ ì—°ê²° ê´€ê³„
{len(indirect_connections)}ê°œì˜ ê°„ì ‘ ì—°ê²° ê´€ê³„ ë°œê²¬

### ë¶„ì„ ê²°ê³¼
ì´ íŠ¸ë ˆì´ìŠ¤ëŠ” {len(similar_trace_ids)}ê°œì˜ ìœ ì‚¬í•œ íŠ¸ë ˆì´ìŠ¤ì™€ ì—°ê´€ë˜ì–´ ìžˆìœ¼ë©°, ì´ {len(indirect_connections)}ê°œì˜ ê°„ì ‘ ì—°ê²°ì„ í†µí•´ ë‹¤ë¥¸ ì—”í‹°í‹°ë“¤ê³¼ ì—°ê²°ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.
"""

    return {
        "long_summary": long_summary_text.strip(),
        "similar_trace_ids": similar_trace_ids,
    }


def cosine_similarity(vec1, vec2):
    v1 = np.array(vec1, dtype=float)
    v2 = np.array(vec2, dtype=float)
    if np.linalg.norm(v1) == 0 or np.linalg.norm(v2) == 0:
        return 0.0
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))


def find_similar_traces(driver, summary_text, top_k=3):
    with driver.session(database=DATABASE) as session:
        # ë¨¼ì € Trace ë…¸ë“œì˜ ì‹¤ì œ ì†ì„±ì„ í™•ì¸
        try:
            # Trace ë…¸ë“œì˜ ì†ì„± í™•ì¸
            result = session.run("MATCH (t:Trace) RETURN keys(t) as keys LIMIT 1")
            record = result.single()
            if record and record["keys"]:
                trace_keys = record["keys"]
                print(f"ðŸ” Trace ë…¸ë“œ ì†ì„±: {trace_keys}")

                # traceId ì†ì„±ì´ ìžˆëŠ”ì§€ í™•ì¸
                if "traceId" in trace_keys:
                    trace_id_prop = "t.traceId"
                elif "trace_id" in trace_keys:
                    trace_id_prop = "t.trace_id"
                else:
                    print("âš ï¸ traceId ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ID() ì‚¬ìš©")
                    trace_id_prop = "id(t)"
            else:
                print("âš ï¸ Trace ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤. ID() ì‚¬ìš©")
                trace_id_prop = "id(t)"
        except Exception as e:
            print(f"âš ï¸ Trace ë…¸ë“œ ì†ì„± í™•ì¸ ì‹¤íŒ¨: {e}. ID() ì‚¬ìš©")
            trace_id_prop = "id(t)"

        query = f"""
            MATCH (s:Summary)-[:SUMMARIZES]->(t:Trace)
            RETURN 
                t.traceId AS trace_id, 
                s.embedding AS embedding
        """
        print(f"ðŸ” ì‹¤í–‰í•  ì¿¼ë¦¬: {query}")

        all_summaries = session.run(query)

        summary_embedding = embedding_model.encode(summary_text)
        similarities = []

        print(
            f"ðŸ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(list(all_summaries))}ê°œì˜ Summaryë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        )

        # all_summariesë¥¼ ë‹¤ì‹œ ê°€ì ¸ì™€ì•¼ í•¨ (ì´ë¯¸ ì†Œë¹„ë¨)
        all_summaries = session.run(query)

        record_count = 0
        for record in all_summaries:
            record_count += 1
            trace_id = record["trace_id"]
            emb = record["embedding"]

            print(
                f"   ðŸ“Š Record {record_count}: trace_id={trace_id}, embedding_type={type(emb)}"
            )

            if isinstance(emb, str):
                try:
                    emb = json.loads(emb)
                except json.JSONDecodeError:
                    print(f"   âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {trace_id}")
                    continue

            if emb is None:
                print(f"   âš ï¸ Embeddingì´ None: {trace_id}")
                continue

            sim = cosine_similarity(summary_embedding, emb)
            similarities.append({"trace_id": trace_id, "similarity": sim})
            print(f"   âœ… ìœ ì‚¬ë„ ê³„ì‚°: {trace_id} = {sim:.4f}")

        print(f"ðŸ“Š ì´ {len(similarities)}ê°œì˜ ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ")
        similarities.sort(key=lambda x: x["similarity"], reverse=True)

        result = similarities[:top_k]
        print(f"ðŸŽ¯ ìƒìœ„ {top_k}ê°œ ê²°ê³¼: {[r['trace_id'] for r in result]}")
        return result


def generate_mitigation_prompt(
    summary_result, structural_similarity, indirect_connections
):
    """
    LLMì—ê²Œ ì•…ì„± í–‰ìœ„ ëŒ€ì‘ ë°©ì•ˆì„ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    summary_text = summary_result.get("summary", "")

    similar_entities = set()
    for s in structural_similarity:
        similar_entities.update(s["common_entities"])

    for c in indirect_connections:
        similar_entities.add(c["e1_name"])
        similar_entities.add(c["e2_name"])

    prompt = f"""
    ë‹¹ì‹ ì€ ë³´ì•ˆ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ì•„ëž˜ íŠ¸ë ˆì´ìŠ¤ ë¶„ì„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ì—… í™˜ê²½ì—ì„œ ë°œê²¬ëœ ì•…ì„± í–‰ìœ„ì— ëŒ€í•œ 
    ì‹¤ì œ ëŒ€ì‘ ë°©ì•ˆì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.

    [íŠ¸ë ˆì´ìŠ¤ ìš”ì•½]
    {summary_text}

    [ì—°ê´€ ì—”í‹°í‹°]
    {', '.join(similar_entities)}

    [ìš”ì²­]
    1. íƒì§€ëœ ì•…ì„± í”„ë¡œì„¸ìŠ¤ ë° íŒŒì¼ ê²©ë¦¬ ë°©ë²•
    2. ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨ ë° ì™¸ë¶€ í†µì‹  í†µì œ ë°©ì•ˆ
    3. ë¡œê·¸/ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê°•í™” ë°©ë²•
    4. í–¥í›„ ìœ ì‚¬ ê³µê²© ì˜ˆë°© ì „ëžµ
    5. ì‹¤ë¬´ìžê°€ ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ë‹¨ê³„ë³„ ëŒ€ì‘ ê¶Œìž¥

    ì‘ë‹µì€ JSON ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìž‘ì„±í•˜ê³ , ë‹¨ê³„ë³„ë¡œ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ìƒì„¸ížˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    ì–¸ì–´ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
    """
    return prompt


def analyze_structural_similarity_no_db(driver, new_trace, prompt_template, top_k=3):
    print("ðŸ” analyze_structural_similarity_no_db ì‹œìž‘...")

    # LLM ìš”ì•½
    print("ðŸ“ LLM ìš”ì•½ ì‹œìž‘...")
    summary_result = summarize_trace_with_llm(new_trace, prompt_template)
    if "error" in summary_result:
        print(f"âŒ LLM ìš”ì•½ ì‹¤íŒ¨: {summary_result['error']}")
        return summary_result

    summary_text = summary_result.get("summary", "")
    print(f"âœ… LLM ìš”ì•½ ì™„ë£Œ: {len(summary_text)} ë¬¸ìž")
    print(
        f"ðŸ“„ ìš”ì•½ ë‚´ìš©: {summary_text[:200]}{'...' if len(summary_text) > 200 else ''}"
    )

    if not summary_text:
        print("âš ï¸ ìš”ì•½ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.")
        return {
            "summary": {"summary": "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"},
            "long_summary": "ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "similar_trace_ids": [],
            "mitigation_suggestions": "ìš”ì•½ì´ ì—†ì–´ ëŒ€ì‘ ë°©ì•ˆì„ ì œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        }

    # ì˜ë¯¸ì  ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤ ê²€ìƒ‰
    print("ðŸ” ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤ ê²€ìƒ‰ ì‹œìž‘...")
    try:
        # Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸
        with driver.session() as session:
            session.run("RETURN 1")

        top_similar_traces = find_similar_traces(driver, summary_text, top_k=top_k)
        similar_ids = [t["trace_id"] for t in top_similar_traces]
        print(f"âœ… ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(similar_ids)}ê°œ")
    except Exception as e:
        print(f"âŒ ìœ ì‚¬ íŠ¸ë ˆì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨ (Neo4j ì—°ê²° ë¬¸ì œ): {e}")
        print("âš ï¸ Neo4j ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        similar_ids = []
        top_similar_traces = []

    print(f"\nðŸ” ì˜ë¯¸ì  ìœ ì‚¬ë„ ìƒìœ„ {len(similar_ids)}ê°œ íŠ¸ë ˆì´ìŠ¤: {similar_ids}\n")

    # êµ¬ì¡°ì  ìœ ì‚¬ì„± ë¶„ì„
    print("ðŸ” êµ¬ì¡°ì  ìœ ì‚¬ì„± ë¶„ì„ ì‹œìž‘...")
    try:
        with driver.session(database=DATABASE) as session:
            # Trace ë…¸ë“œì˜ ì‹¤ì œ ì†ì„± í™•ì¸
            try:
                result = session.run("MATCH (t:Trace) RETURN keys(t) as keys LIMIT 1")
                record = result.single()
                if record and record["keys"]:
                    trace_keys = record["keys"]
                    if "traceId" in trace_keys:
                        trace_id_prop = "t.traceId"
                    elif "trace_id" in trace_keys:
                        trace_id_prop = "t.trace_id"
                    else:
                        trace_id_prop = "id(t)"
                else:
                    trace_id_prop = "id(t)"
            except Exception as e:
                print(f"âš ï¸ Trace ë…¸ë“œ ì†ì„± í™•ì¸ ì‹¤íŒ¨: {e}. ID() ì‚¬ìš©")
                trace_id_prop = "id(t)"

            res = session.run(
                f"""
                MATCH (s:Summary)-[:SUMMARIZES]->(t:Trace)
                WHERE t.traceId IN $trace_ids
                OPTIONAL MATCH (s)-[:USES_TECHNIQUE]->(tech)
                OPTIONAL MATCH (t)<-[:PARTICIPATED_IN]-(ent)
                RETURN 
                    t.traceId AS trace_id,
                    collect(DISTINCT
                        CASE labels(ent)[0]
                            WHEN 'Process' THEN ent.processName
                            WHEN 'File' THEN ent.filePath
                            WHEN 'User' THEN ent.userName
                            WHEN 'Ip' THEN ent.ipAddress
                            WHEN 'Registry' THEN ent.keyPath
                            ELSE null
                        END
                    ) AS entities,
                    collect(DISTINCT tech.name) AS techniques

            """,
                trace_ids=similar_ids,
            )

            trace_entities = summary_result.get("key_entities", [])
            new_entities = set(
                e["value"].strip().lower().replace("\\", "/")
                for e in trace_entities
                if isinstance(e, dict) and "value" in e
            )

            comparisons = []
            for record in res:

                db_entities = set(
                    (e or "").strip().lower().replace("\\", "/")
                    for e in record["entities"]
                    if e and e != "-"
                )
                # ê³µí†µ ì—”í‹°í‹°
                common_entities = new_entities & db_entities

                comparisons.append(
                    {
                        "trace_id": record["trace_id"],
                        "common_entities": list(common_entities),
                        "entity_match_count": len(common_entities),
                    }
                )

            comparisons.sort(key=lambda x: (x["entity_match_count"]), reverse=True)

            # ê°„ì ‘ ì—°ê²° íƒìƒ‰
            with driver.session(database=DATABASE) as session:
                query = f"""
                    UNWIND $trace_ids AS trace_id
                    MATCH (s:Summary)-[:SUMMARIZES]->(t:Trace)
                    WHERE t.traceId = trace_id
                    OPTIONAL MATCH (t)<-[:PARTICIPATED_IN]-(ent)
                    WITH collect(DISTINCT
                        CASE labels(ent)[0]
                            WHEN 'Process' THEN ent.processName
                            WHEN 'File' THEN ent.filePath
                            WHEN 'User' THEN ent.userName
                            WHEN 'Ip' THEN ent.ipAddress
                            WHEN 'Registry' THEN ent.keyPath
                            ELSE null
                        END
                    ) AS groupEntities
                    UNWIND groupEntities AS e1
                    UNWIND groupEntities AS e2
                    WITH e1, e2 WHERE e1 IS NOT NULL AND e2 IS NOT NULL AND e1 < e2
                    MATCH path = shortestPath(
                        (n1)-[*..2]-(n2)
                    )
                    WHERE 
                        ( (labels(n1)[0] = 'Process' AND n1.processName = e1) OR
                        (labels(n1)[0] = 'File' AND n1.filePath = e1) OR
                        (labels(n1)[0] = 'User' AND n1.userName = e1) OR
                        (labels(n1)[0] = 'Ip' AND n1.ipAddress = e1) OR
                        (labels(n1)[0] = 'Registry' AND n1.keyPath = e1) )
                    AND
                        ( (labels(n2)[0] = 'Process' AND n2.processName = e2) OR
                        (labels(n2)[0] = 'File' AND n2.filePath = e2) OR
                        (labels(n2)[0] = 'User' AND n2.userName = e2) OR
                        (labels(n2)[0] = 'Ip' AND n2.ipAddress = e2) OR
                        (labels(n2)[0] = 'Registry' AND n2.keyPath = e2) )
                    RETURN e1 AS e1_name, e2 AS e2_name,
                        length(path) AS hops,
                        [n IN nodes(path) | 
                            labels(n)[0] + ':' + coalesce(n.name, n.processName, n.filePath, n.userName, n.ipAddress, n.keyPath, '') 
                        ] AS path_nodes
                    LIMIT 50

                """
                indirect_connections_result = session.run(query, trace_ids=similar_ids)
                indirect_connections_raw = [
                    r.data() for r in indirect_connections_result
                ]

                # ì¤‘ë³µ ì œê±° (ì–‘ë°©í–¥ ì—°ê²° ê³ ë ¤)
                seen_connections = set()
                indirect_connections = []

                for conn in indirect_connections_raw:
                    e1_name = conn["e1_name"]
                    e2_name = conn["e2_name"]
                    connection_key = tuple(sorted([e1_name, e2_name]))

                    if connection_key not in seen_connections:
                        seen_connections.add(connection_key)
                        indirect_connections.append(conn)

        print(
            f"âœ… êµ¬ì¡°ì  ìœ ì‚¬ì„± ë¶„ì„ ì™„ë£Œ: {len(comparisons)}ê°œ ë¹„êµ, {len(indirect_connections)}ê°œ ê°„ì ‘ ì—°ê²°"
        )

    except Exception as e:
        print(f"âŒ êµ¬ì¡°ì  ìœ ì‚¬ì„± ë¶„ì„ ì‹¤íŒ¨ (Neo4j ì—°ê²° ë¬¸ì œ): {e}")
        print("âš ï¸ Neo4j ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        comparisons = []
        indirect_connections = []

        # ìƒì„¸ ìš”ì•½ ìƒì„±
        print("ðŸ“ ìƒì„¸ ìš”ì•½ ìƒì„± ì‹œìž‘...")
        try:
            if similar_ids:
                long_summary_result = long_summary(
                    driver,
                    summary_text,
                    comparisons,
                    indirect_connections,
                    top_similar_traces,
                    top_k=3,
                )
            else:
                # Neo4j ì—†ì´ ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
                long_summary_text = f"""
## ìƒì„¸ ë¶„ì„ ìš”ì•½

### ì›ë³¸ íŠ¸ë ˆì´ìŠ¤ ìš”ì•½
{summary_text}

### ë¶„ì„ ê²°ê³¼
ì´ íŠ¸ë ˆì´ìŠ¤ëŠ” ì•…ì„± í™œë™ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤. Sigma ë£° ë§¤ì¹­ì„ í†µí•´ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í–‰ìœ„ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- PowerShell Base64 ì¸ì½”ë”©ëœ ëª…ë ¹ì–´ ì‹¤í–‰
- ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í”„ë¡œì„¸ìŠ¤ ìƒì„± íŒ¨í„´
- Sigma ë£° ë§¤ì¹­: {summary_result.get('attack_techniques', [])}

### ë³´ì•ˆ ê¶Œê³ ì‚¬í•­
1. í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ ì¦‰ì‹œ ê²©ë¦¬
2. ì‹œìŠ¤í…œ ì „ì²´ ìŠ¤ìº” ìˆ˜í–‰
3. ë„¤íŠ¸ì›Œí¬ íŠ¸ëž˜í”½ ëª¨ë‹ˆí„°ë§ ê°•í™”
4. ë¡œê·¸ ë¶„ì„ì„ í†µí•œ ì¶”ê°€ ìœ„í˜‘ íƒì§€
"""
                long_summary_result = {
                    "long_summary": long_summary_text.strip(),
                    "similar_trace_ids": similar_ids,
                }
            print("âœ… ìƒì„¸ ìš”ì•½ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ìƒì„¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            long_summary_result = {
                "long_summary": "ìƒì„¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨",
                "similar_trace_ids": similar_ids,
            }

        # ëŒ€ì‘ ì œì•ˆ ìƒì„±
        print("ðŸ›¡ï¸ ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ì‹œìž‘...")
        try:
            if comparisons or indirect_connections:
                mitigation_prompt = generate_mitigation_prompt(
                    summary_result, comparisons, indirect_connections
                )
                mitigation_response = llm.invoke(mitigation_prompt)
                mitigation_text = mitigation_response.content
            else:
                # Neo4j ì—†ì´ ê¸°ë³¸ ëŒ€ì‘ ë°©ì•ˆ ìƒì„±
                mitigation_text = f"""
## ë³´ì•ˆ ëŒ€ì‘ ë°©ì•ˆ

### ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
1. **í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬**: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í”„ë¡œì„¸ìŠ¤ ì¦‰ì‹œ ì¢…ë£Œ ë° ê²©ë¦¬
2. **ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨**: ì™¸ë¶€ í†µì‹  ì°¨ë‹¨ ë° ë°©í™”ë²½ ê·œì¹™ ê°•í™”
3. **ì‹œìŠ¤í…œ ìŠ¤ìº”**: ì „ì²´ ì‹œìŠ¤í…œ ì•…ì„±ì½”ë“œ ìŠ¤ìº” ìˆ˜í–‰

### ì¤‘ê¸° ëŒ€ì‘ ë°©ì•ˆ
1. **ë¡œê·¸ ë¶„ì„**: ì‹œìŠ¤í…œ ë¡œê·¸ ì „ì²´ ë¶„ì„ì„ í†µí•œ ì¶”ê°€ ìœ„í˜‘ íƒì§€
2. **ì‚¬ìš©ìž ê³„ì • ê²€í† **: ê´€ë ¨ ì‚¬ìš©ìž ê³„ì • ë³´ì•ˆ ìƒíƒœ ì ê²€
3. **ì‹œìŠ¤í…œ íŒ¨ì¹˜**: ë³´ì•ˆ íŒ¨ì¹˜ ì ìš© ë° ì·¨ì•½ì  ì ê²€

### ìž¥ê¸° ì˜ˆë°© ì „ëžµ
1. **ëª¨ë‹ˆí„°ë§ ê°•í™”**: ì‹¤ì‹œê°„ ë³´ì•ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•
2. **ì‚¬ìš©ìž êµìœ¡**: ë³´ì•ˆ ì¸ì‹ êµìœ¡ ë° ì •ì±… ìˆ˜ë¦½
3. **ì •ê¸° ì ê²€**: ì •ê¸°ì ì¸ ë³´ì•ˆ ì ê²€ ë° ì¹¨íˆ¬ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰

### ë¶„ì„ëœ ìœ„í˜‘ ì •ë³´
- **íƒì§€ëœ ê³µê²© ê¸°ë²•**: {summary_result.get('attack_techniques', ['Unknown'])}
- **ì£¼ìš” í”„ë¡œì„¸ìŠ¤**: cmd.exe, powershell.exe
- **ì˜ì‹¬ í™œë™**: Base64 ì¸ì½”ë”©ëœ ëª…ë ¹ì–´ ì‹¤í–‰
"""
            print("âœ… ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            mitigation_text = "ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ì‹¤íŒ¨"

        result = {
            "summary": summary_result,
            "long_summary": long_summary_result["long_summary"],
            "similar_trace_ids": long_summary_result["similar_trace_ids"],
            "mitigation_suggestions": mitigation_text,
        }

        print("ðŸŽ‰ analyze_structural_similarity_no_db ì™„ë£Œ")
        return result


#     trace_path = "C:\\Users\\KISIA\\Downloads\\data\\T1018.json"
